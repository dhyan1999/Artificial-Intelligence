{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy : Tokenization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlwn1rb6u8bhq6Co/SU8Va",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhyan1999/Artificial-Intelligence/blob/master/Natural%20Language%20Processing/Spacy_Tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_orhDYCs10Un"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3jS2nYf2JYt"
      },
      "source": [
        "# It will know that we are doing processing in english language and load the language\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA5E6Whf8A_q"
      },
      "source": [
        "docx = nlp(\"Spacy is good library\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkW1BS3T-Lw9",
        "outputId": "4d3870b2-4841-4347-8ece-dc18a3ccde9e"
      },
      "source": [
        "docx"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Spacy is good library"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFOT4vPS-Mxw"
      },
      "source": [
        "docx1 = nlp(u\"Spacy is good library same as NLTK\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axNyeiJ5-Q8T",
        "outputId": "e918ca20-7075-4d83-b826-c99ef5b663df"
      },
      "source": [
        "docx1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Spacy is good library same as NLTK"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn9ItGTh-Rp1"
      },
      "source": [
        "myfile = open(\"mydocument.txt\").read()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs7_N6Yj_7VQ"
      },
      "source": [
        "docx3 = nlp(myfile)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CPJxXpA__OC",
        "outputId": "edb90550-ef80-4bc7-ed72-1c964eb3ec9f"
      },
      "source": [
        "docx3"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "This example in train_entity_linker.py shows you how the model learns to disambiguate \"Russ Cochran\" the golfer (Q2146908) from the publisher (Q7381115). Note that it is just a toy example: a realistic application would require a larger knowledge base with accurate prior frequencies (as you can get by running the Wikipedia/Wikidata scripts)\n",
              "\n",
              "Amnd ofcourse you would need many more sentences and lexical variety to expect the Machine Learning model to pick up proper clues and generalize efficiently to unseen text."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECUTGxvY__8r",
        "outputId": "570c205b-2ed9-4431-8758-d4523b9f9046"
      },
      "source": [
        "# Sentence Tokens\n",
        "for num,sentence in enumerate(docx3.sents):\n",
        "  print(f'{num}: {sentence}')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: This example in train_entity_linker.py shows you how the model learns to disambiguate \"Russ Cochran\" the golfer (Q2146908) from the publisher (Q7381115).\n",
            "1: Note that it is just a toy example: a realistic application would require a larger knowledge base with accurate prior frequencies (as you can get by running the Wikipedia/Wikidata scripts)\n",
            "\n",
            "\n",
            "2: Amnd ofcourse you would need many more sentences and lexical variety to expect the Machine Learning model to pick up proper clues and generalize efficiently to unseen text.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO8o1DMGBH1F",
        "outputId": "45dd3468-0b3f-4d19-ed70-d48af3b8f811"
      },
      "source": [
        "# Word Token\n",
        "for token in docx1:\n",
        "  print(token.text)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spacy\n",
            "is\n",
            "good\n",
            "library\n",
            "same\n",
            "as\n",
            "NLTK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlNiruLeBdYh"
      },
      "source": [
        "# List of Word tokens\n",
        "docx1token = [token.text for token in docx1]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWcaDOdhB8ev",
        "outputId": "a5c825cc-aac8-4cd1-ac21-84d83616f12b"
      },
      "source": [
        "docx1token"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Spacy', 'is', 'good', 'library', 'same', 'as', 'NLTK']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Nb1sHZY-CHaw",
        "outputId": "2657cb0f-6960-488b-a6d7-f5e46e59e39d"
      },
      "source": [
        "docx1token[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Spacy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93tIFem6CIfz",
        "outputId": "b63b2214-3bcd-4207-d644-c413bb0ae9eb"
      },
      "source": [
        "# Another way of doing\n",
        "docx1.text.split(\" \")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Spacy', 'is', 'good', 'library', 'same', 'as', 'NLTK']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oewGmKDoCYV0",
        "outputId": "bc9617e3-22c3-4b7c-f63e-b37d6a8365e2"
      },
      "source": [
        "# .shape    ===> check the shape of the word\n",
        "# .is_alpha ===> check it is alphabet or not\n",
        "# .is_stop  ===> check it is stop word or not\n",
        "for word in docx1:\n",
        "  print()\n",
        "  print(\"Token =>\",word.text,\"\\nShape =>\",word.shape,\"\\nAlphabet =>\",word.is_alpha,\"\\nStopWord =>\",word.is_stop)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Token => Spacy \n",
            "Shape => 16072095006890171862 \n",
            "Alphabet => True \n",
            "StopWord => False\n",
            "\n",
            "Token => is \n",
            "Shape => 4370460163704169311 \n",
            "Alphabet => True \n",
            "StopWord => True\n",
            "\n",
            "Token => good \n",
            "Shape => 13110060611322374290 \n",
            "Alphabet => True \n",
            "StopWord => False\n",
            "\n",
            "Token => library \n",
            "Shape => 13110060611322374290 \n",
            "Alphabet => True \n",
            "StopWord => False\n",
            "\n",
            "Token => same \n",
            "Shape => 13110060611322374290 \n",
            "Alphabet => True \n",
            "StopWord => True\n",
            "\n",
            "Token => as \n",
            "Shape => 4370460163704169311 \n",
            "Alphabet => True \n",
            "StopWord => True\n",
            "\n",
            "Token => NLTK \n",
            "Shape => 13862804199789047564 \n",
            "Alphabet => True \n",
            "StopWord => False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3mOvYwJCrgV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}